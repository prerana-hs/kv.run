{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1fab4dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "cos = torch.load('cos')\n",
    "sin = torch.load('sin')\n",
    "rotary_pos_emb_causal = torch.load('rotary_pos_emb_causal')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb01ed8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True, device='cuda:0')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rotary_pos_emb_flashinfer = torch.cat((cos, sin), dim=1).view(7, 32, 2)\n",
    "# rotary_pos_emb_flashinfer = torch.cat((cos.squeeze(2), sin.squeeze(2)), dim=2)\n",
    "rotary_pos_emb_flashinfer = torch.cat((cos.transpose(1, 2), sin.transpose(1, 2)), dim=2)\n",
    "torch.all(rotary_pos_emb_flashinfer == rotary_pos_emb_causal[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75fc5d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "key_layer_before_causal = torch.load(\"key_layer_before_causal\")\n",
    "query_layer_before_causal = torch.load(\"query_layer_before_causal\")\n",
    "key_layer_before_flashinfer = torch.load(\"key_layer_before_flashinfer\")\n",
    "query_layer_before_flashinfer = torch.load(\"query_layer_before_flashinfer\")\n",
    "key_layer_after_causal = torch.load(\"key_layer_after_causal\")\n",
    "query_layer_after_causal = torch.load(\"query_layer_after_causal\")\n",
    "key_layer_after_flashinfer = torch.load(\"key_layer_after_flashinfer\")\n",
    "query_layer_after_flashinfer = torch.load(\"query_layer_after_flashinfer\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "85f35daa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([7, 32, 128]), torch.Size([7, 32, 2]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_layer_before_flashinfer.shape, rotary_pos_emb_flashinfer.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7e406b33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 7, 128])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = apply_rotary_pos_emb(key_layer_before_flashinfer.transpose(0, 1).unsqueeze(0), rotary_pos_emb_flashinfer.unsqueeze(0))\n",
    "assert_close(res, key_layer_after_causal, 1e-2, 3e-3)\n",
    "res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae763c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_rotary_pos_emb(x: torch.Tensor, rope_cache: torch.Tensor) -> torch.Tensor:\n",
    "    # x: [b, np, sq, hn]\n",
    "    b, np, sq, hn = x.size(0), x.size(1), x.size(2), x.size(3)\n",
    "    rot_dim = rope_cache.shape[-2] * 2\n",
    "    x, x_pass = x[..., :rot_dim], x[..., rot_dim:]\n",
    "    # truncate to support variable sizes\n",
    "    rope_cache = rope_cache[:, :sq]\n",
    "    xshaped = x.reshape(b, np, sq, rot_dim // 2, 2)\n",
    "    rope_cache = rope_cache.view(-1, 1, sq, xshaped.size(3), 2)\n",
    "    x_out2 = torch.stack(\n",
    "        [\n",
    "            xshaped[..., 0] * rope_cache[..., 0] - xshaped[..., 1] * rope_cache[..., 1],\n",
    "            xshaped[..., 1] * rope_cache[..., 0] + xshaped[..., 0] * rope_cache[..., 1],\n",
    "        ],\n",
    "        -1,\n",
    "    )\n",
    "    x_out2 = x_out2.flatten(3)\n",
    "    return torch.cat((x_out2, x_pass), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "857eb249",
   "metadata": {},
   "outputs": [],
   "source": [
    "key_after_rope = apply_rotary_pos_emb(key_layer_before_causal, rotary_pos_emb_causal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4545d46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = key_layer_before_causal\n",
    "rope_cache = rotary_pos_emb_causal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "15c0ad6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "b, np, sq, hn = x.size(0), x.size(1), x.size(2), x.size(3)\n",
    "rot_dim = rope_cache.shape[-2] * 2\n",
    "x, x_pass = x[..., :rot_dim], x[..., rot_dim:]\n",
    "# truncate to support variable sizes\n",
    "rope_cache = rope_cache[:, :sq]\n",
    "xshaped = x.reshape(b, np, sq, rot_dim // 2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4f039ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "rope_cache = rope_cache.view(-1, 1, sq, xshaped.size(3), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1ba04686",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = xshaped[..., 0] * rope_cache[..., 0] - xshaped[..., 1] * rope_cache[..., 1]\n",
    "x2 = xshaped[..., 1] * rope_cache[..., 0] + xshaped[..., 0] * rope_cache[..., 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "226f01a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 2, 7, 32]), 64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1.shape, rot_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1b6aec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "610ce086",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assert_close(a, b, rtol, atol):\n",
    "    # rtol, atol = {\n",
    "    #     torch.float16: (1e-2, 5e-2),\n",
    "    #     torch.bfloat16: (8e-3, 8e-3),\n",
    "    # }[a.dtype]\n",
    "    torch.testing.assert_close(a, b, rtol=rtol, atol=atol)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
